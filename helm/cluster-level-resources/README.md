# cluster-level-resources

![Version: 0.6.1](https://img.shields.io/badge/Version-0.6.1-informational?style=flat-square) ![Type: application](https://img.shields.io/badge/Type-application-informational?style=flat-square) ![AppVersion: 1.17.0](https://img.shields.io/badge/AppVersion-1.17.0-informational?style=flat-square)

An app-of-apps Helm chart that allows for flexible deployment of resources that support Gen3

## Values

| Key | Type | Default | Description |
|-----|------|---------|-------------|
| accountNumber | string | `"xxxxxxxxxxxx"` |  |
| alb-controller.configuration.enabled | bool | `false` |  |
| alb-controller.enabled | bool | `false` |  |
| alb-controller.targetRevision | string | `"1.11.0"` |  |
| alloy-configmap-data | string | `"logging {\n  level    = \"info\"\n  format   = \"json\"\n  write_to = [loki.write.endpoint.receiver]\n}\n\n/////////////////////// OTLP START ///////////////////////\n\notelcol.receiver.otlp \"default\" {\n  grpc {}\n  http {}\n\n  output {\n    metrics = [otelcol.processor.batch.default.input]\n    traces = [otelcol.processor.batch.default.input]\n  }\n}\n\notelcol.processor.batch \"default\" {\n  output {\n    metrics = [otelcol.exporter.prometheus.default.input]\n    traces  = [otelcol.exporter.otlp.tempo.input]\n  }\n}\n\notelcol.exporter.prometheus \"default\" {\n  forward_to = [prometheus.remote_write.default.receiver]\n}\n\notelcol.exporter.otlp \"tempo\" {\n  client {\n    endpoint = \"http://monitoring-tempo-distributor.monitoring:4317\"\n    // Configure TLS settings for communicating with the endpoint.\n    tls {\n        // The connection is insecure.\n        insecure = true\n        // Do not verify TLS certificates when connecting.\n        insecure_skip_verify = true\n    }\n  }\n}\n\n\n/////////////////////// OTLP END ///////////////////////\n\n// discover all pods, to be used later in this config\ndiscovery.kubernetes \"pods\" {\n  role = \"pod\"\n}\n\n// discover all services, to be used later in this config\ndiscovery.kubernetes \"services\" {\n  role = \"service\"\n}\n\n// discover all nodes, to be used later in this config\ndiscovery.kubernetes \"nodes\" {\n  role = \"node\"\n}\n\n// Generic scrape of any pod with Annotation \"prometheus.io/scrape: true\"\ndiscovery.relabel \"annotation_autodiscovery_pods\" {\n  targets = discovery.kubernetes.pods.targets\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_scrape\"]\n    regex = \"true\"\n    action = \"keep\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_job\"]\n    action = \"replace\"\n    target_label = \"job\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_instance\"]\n    action = \"replace\"\n    target_label = \"instance\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_path\"]\n    action = \"replace\"\n    target_label = \"__metrics_path__\"\n  }\n\n  // Choose the pod port\n  // The discovery generates a target for each declared container port of the pod.\n  // If the metricsPortName annotation has value, keep only the target where the port name matches the one of the annotation.\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_port_name\"]\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_portName\"]\n    regex = \"(.+)\"\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_port_name\"]\n    action = \"keepequal\"\n    target_label = \"__tmp_port\"\n  }\n\n  // If the metrics port number annotation has a value, override the target address to use it, regardless whether it is\n  // one of the declared ports on that Pod.\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_port\", \"__meta_kubernetes_pod_ip\"]\n    regex = \"(\\\\d+);(([A-Fa-f0-9]{1,4}::?){1,7}[A-Fa-f0-9]{1,4})\"\n    replacement = \"[$2]:$1\" // IPv6\n    target_label = \"__address__\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_port\", \"__meta_kubernetes_pod_ip\"]\n    regex = \"(\\\\d+);((([0-9]+?)(\\\\.|$)){4})\" // IPv4, takes priority over IPv6 when both exists\n    replacement = \"$2:$1\"\n    target_label = \"__address__\"\n  }\n\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_annotation_prometheus_io_scheme\"]\n    action = \"replace\"\n    target_label = \"__scheme__\"\n  }\n\n\n  // add labels\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_name\"]\n    target_label = \"pod\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_name\"]\n    target_label = \"container\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_controller_name\"]\n    target_label = \"controller\"\n  }\n\n  rule {\n    source_labels = [\"__meta_kubernetes_namespace\"]\n    target_label = \"namespace\"\n  }\n\n\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_label_app\"]\n    target_label = \"app\"\n  }\n\n  // map all labels\n  rule {\n    action = \"labelmap\"\n    regex  = \"__meta_kubernetes_pod_label_(.+)\"\n  }\n}\n\n// Generic scrape of any service with\n// Annotation Autodiscovery\ndiscovery.relabel \"annotation_autodiscovery_services\" {\n  targets = discovery.kubernetes.services.targets\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_scrape\"]\n    regex = \"true\"\n    action = \"keep\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_job\"]\n    action = \"replace\"\n    target_label = \"job\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_instance\"]\n    action = \"replace\"\n    target_label = \"instance\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_path\"]\n    action = \"replace\"\n    target_label = \"__metrics_path__\"\n  }\n\n  // Choose the service port\n  rule {\n    source_labels = [\"__meta_kubernetes_service_port_name\"]\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_portName\"]\n    regex = \"(.+)\"\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_port_name\"]\n    action = \"keepequal\"\n    target_label = \"__tmp_port\"\n  }\n\n  rule {\n    source_labels = [\"__meta_kubernetes_service_port_number\"]\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_port\"]\n    regex = \"(.+)\"\n    target_label = \"__tmp_port\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_port_number\"]\n    action = \"keepequal\"\n    target_label = \"__tmp_port\"\n  }\n\n  rule {\n    source_labels = [\"__meta_kubernetes_service_annotation_prometheus_io_scheme\"]\n    action = \"replace\"\n    target_label = \"__scheme__\"\n  }\n}\n\nprometheus.scrape \"metrics\" {\n  job_name   = \"integrations/autodiscovery_metrics\"\n  targets  = concat(discovery.relabel.annotation_autodiscovery_pods.output, discovery.relabel.annotation_autodiscovery_services.output)\n  honor_labels = true\n  clustering {\n    enabled = true\n  }\n  forward_to = [prometheus.relabel.metrics_service.receiver]\n}\n\n\n// Node Exporter\n// TODO: replace with https://grafana.com/docs/alloy/latest/reference/components/prometheus.exporter.unix/\ndiscovery.relabel \"node_exporter\" {\n  targets = discovery.kubernetes.pods.targets\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_label_app_kubernetes_io_instance\"]\n    regex = \"monitoring-extras\"\n    action = \"keep\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_label_app_kubernetes_io_name\"]\n    regex = \"node-exporter\"\n    action = \"keep\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_node_name\"]\n    action = \"replace\"\n    target_label = \"instance\"\n  }\n}\n\nprometheus.scrape \"node_exporter\" {\n  job_name   = \"integrations/node_exporter\"\n  targets  = discovery.relabel.node_exporter.output\n  scrape_interval = \"60s\"\n  clustering {\n    enabled = true\n  }\n  forward_to = [prometheus.relabel.node_exporter.receiver]\n}\n\nprometheus.relabel \"node_exporter\" {\n  rule {\n    source_labels = [\"__name__\"]\n    regex = \"up|node_cpu.*|node_network.*|node_exporter_build_info|node_filesystem.*|node_memory.*|process_cpu_seconds_total|process_resident_memory_bytes\"\n    action = \"keep\"\n  }\n  forward_to = [prometheus.relabel.metrics_service.receiver]\n}\n\n\n// cAdvisor\n// discovery.relabel \"cadvisor\" {\n//  targets = discovery.kubernetes.nodes.targets\n//  rule {\n//    target_label = \"__address__\"\n//    replacement  = \"kubernetes.default.svc.cluster.local:443\"\n//  }\n//  rule {\n//    source_labels = [\"__meta_kubernetes_node_name\"]\n//    regex         = \"(.+)\"\n//    replacement   = \"/api/v1/nodes/${1}/proxy/metrics/cadvisor\"\n//    target_label  = \"__metrics_path__\"\n//  }\n// }\n\n// prometheus.scrape \"cadvisor\" {\n//  job_name   = \"integrations/kubernetes/cadvisor\"\n//  targets    = discovery.relabel.cadvisor.output\n//  scheme     = \"https\"\n//  scrape_interval = \"60s\"\n//  bearer_token_file = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n//  tls_config {\n//    insecure_skip_verify = true\n//  }\n//  clustering {\n//    enabled = true\n//  }\n//  forward_to = [prometheus.relabel.cadvisor.receiver]\n//}\n\n//prometheus.relabel \"cadvisor\" {\n//  rule {\n//    source_labels = [\"__name__\"]\n//    regex = \"up|container_cpu_cfs_periods_total|container_cpu_cfs_throttled_periods_total|container_cpu_usage_seconds_total|container_fs_reads_bytes_total|container_fs_reads_total|container_fs_writes_bytes_total|container_fs_writes_total|container_memory_cache|container_memory_rss|container_memory_swap|container_memory_working_set_bytes|container_network_receive_bytes_total|container_network_receive_packets_dropped_total|container_network_receive_packets_total|container_network_transmit_bytes_total|container_network_transmit_packets_dropped_total|container_network_transmit_packets_total|machine_memory_bytes\"\n//    action = \"keep\"\n//  }\n//  forward_to = [prometheus.relabel.metrics_service.receiver]\n// }\n\n// Logs from all pods\ndiscovery.relabel \"all_pods\" {\n  targets = discovery.kubernetes.pods.targets\n  rule {\n    source_labels = [\"__meta_kubernetes_namespace\"]\n    target_label = \"namespace\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_name\"]\n    target_label = \"pod\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_container_name\"]\n    target_label = \"container\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_controller_name\"]\n    target_label = \"controller\"\n  }\n\n  rule {\n    source_labels = [\"__meta_kubernetes_pod_label_app\"]\n    target_label = \"app\"\n  }\n\n  // map all labels\n  rule {\n    action = \"labelmap\"\n    regex  = \"__meta_kubernetes_pod_label_(.+)\"\n  }\n\n}\n\nloki.source.kubernetes \"pods\" {\n  targets = discovery.relabel.all_pods.output\n  forward_to = [loki.write.endpoint.receiver]\n}\n\n// kube-state-metrics\ndiscovery.relabel \"relabel_kube_state_metrics\" {\n  targets = discovery.kubernetes.services.targets\n  rule {\n    source_labels = [\"__meta_kubernetes_namespace\"]\n    regex = \"monitoring\"\n    action = \"keep\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_service_name\"]\n    regex = \"monitoring-extras-kube-state-metrics\"\n    action = \"keep\"\n  }\n}\n\nprometheus.scrape \"kube_state_metrics\" {\n  targets = discovery.relabel.relabel_kube_state_metrics.output\n  job_name = \"kube-state-metrics\"\n  metrics_path = \"/metrics\"\n  forward_to = [prometheus.remote_write.default.receiver]\n}\n\n// Kubelet\ndiscovery.relabel \"kubelet\" {\n  targets = discovery.kubernetes.nodes.targets\n  rule {\n    target_label = \"__address__\"\n    replacement  = \"kubernetes.default.svc.cluster.local:443\"\n  }\n  rule {\n    source_labels = [\"__meta_kubernetes_node_name\"]\n    regex         = \"(.+)\"\n    replacement   = \"/api/v1/nodes/${1}/proxy/metrics\"\n    target_label  = \"__metrics_path__\"\n  }\n}\n\nprometheus.scrape \"kubelet\" {\n  job_name   = \"integrations/kubernetes/kubelet\"\n  targets  = discovery.relabel.kubelet.output\n  scheme   = \"https\"\n  scrape_interval = \"60s\"\n  bearer_token_file = \"/var/run/secrets/kubernetes.io/serviceaccount/token\"\n  tls_config {\n    insecure_skip_verify = true\n  }\n  clustering {\n    enabled = true\n  }\n  forward_to = [prometheus.relabel.kubelet.receiver]\n}\n\nprometheus.relabel \"kubelet\" {\n  rule {\n    source_labels = [\"__name__\"]\n    regex = \"up|container_cpu_usage_seconds_total|kubelet_certificate_manager_client_expiration_renew_errors|kubelet_certificate_manager_client_ttl_seconds|kubelet_certificate_manager_server_ttl_seconds|kubelet_cgroup_manager_duration_seconds_bucket|kubelet_cgroup_manager_duration_seconds_count|kubelet_node_config_error|kubelet_node_name|kubelet_pleg_relist_duration_seconds_bucket|kubelet_pleg_relist_duration_seconds_count|kubelet_pleg_relist_interval_seconds_bucket|kubelet_pod_start_duration_seconds_bucket|kubelet_pod_start_duration_seconds_count|kubelet_pod_worker_duration_seconds_bucket|kubelet_pod_worker_duration_seconds_count|kubelet_running_container_count|kubelet_running_containers|kubelet_running_pod_count|kubelet_running_pods|kubelet_runtime_operations_errors_total|kubelet_runtime_operations_total|kubelet_server_expiration_renew_errors|kubelet_volume_stats_available_bytes|kubelet_volume_stats_capacity_bytes|kubelet_volume_stats_inodes|kubelet_volume_stats_inodes_used|kubernetes_build_info|namespace_workload_pod|rest_client_requests_total|storage_operation_duration_seconds_count|storage_operation_errors_total|volume_manager_total_volumes\"\n    action = \"keep\"\n  }\n  forward_to = [prometheus.relabel.metrics_service.receiver]\n}\n\n// Cluster Events\nloki.source.kubernetes_events \"cluster_events\" {\n  job_name   = \"integrations/kubernetes/eventhandler\"\n  log_format = \"logfmt\"\n  forward_to = [loki.write.endpoint.receiver]\n}\n\n\n// Why is this needed?\nprometheus.relabel \"metrics_service\" {\n  forward_to = [prometheus.remote_write.default.receiver]\n}\n\n\n// Write Endpoints\n// prometheus write endpoint\nprometheus.remote_write \"default\" {\n  external_labels = {\n    cluster = \"{{ .Values.cluster }}\",\n    project = \"{{ .Values.project }}\",\n  }\n  endpoint {\n    url = \"https://mimir.planx-pla.net/api/v1/push\"\n\n    headers = {\n      \"X-Scope-OrgID\" = \"anonymous\",\n    }\n\n  }\n}\n\n// loki write endpoint\nloki.write \"endpoint\" {\n  external_labels =  {\n    cluster = \"{{ .Values.cluster }}\",\n    project = \"{{ .Values.project }}\",\n  }\n  endpoint {\n    url = \"https://loki.planx-pla.net/loki/api/v1/push\"\n  }\n}\n"` |  |
| aws-s3-mountpoint.configuration.enabled | bool | `false` |  |
| aws-s3-mountpoint.enabled | bool | `false` |  |
| aws-s3-mountpoint.targetRevision | string | `"1.11.0"` |  |
| calico.configuration.enabled | bool | `false` |  |
| calico.enabled | bool | `false` |  |
| calico.targetRevision | string | `"v3.29.1"` |  |
| cluster | string | `"unfunded"` |  |
| configuration.configurationRepo | string | `"https://github.com/uc-cdis/gen3-gitops"` |  |
| configuration.configurationRevision | string | `"master"` |  |
| coreDNS.configuration.enabled | bool | `false` |  |
| coreDNS.enabled | bool | `false` |  |
| coreDNS.targetRevision | string | `"v1.37.0"` |  |
| ebs-csi-driver.configuration.enabled | bool | `false` |  |
| ebs-csi-driver.enabled | bool | `false` |  |
| ebs-csi-driver.targetRevision | string | `"2.38.1"` |  |
| eksClusterEndpoint | string | `""` |  |
| fluentd-configmap-data | string | `"<label @FLUENT_LOG>\n  <match fluent.**>\n    @type null\n  </match>\n</label>\n\n\n<source>\n  @type tail\n  @id in_tail_container_logs\n  path /var/log/containers/*.log\n  pos_file /var/log/fluentd-containers.log.pos\n  tag \"#{ENV['FLUENT_CONTAINER_TAIL_TAG'] || 'kubernetes.*'}\"\n  exclude_path \"#{ENV['FLUENT_CONTAINER_TAIL_EXCLUDE_PATH'] || use_default}\"\n  read_from_head true\n  <parse>\n    @type \"#{ENV['FLUENT_CONTAINER_TAIL_PARSER_TYPE'] || 'json'}\"\n    time_format %Y-%m-%dT%H:%M:%S.%NZ\n  </parse>\n</source>\n\n<source>\n  @type tail\n  path /var/log/messages\n  pos_file /var/log/host-messages.log.pos\n  <parse>\n    @type syslog\n  </parse>\n  tag host.messages\n</source>\n\n\n<source>\n  @type tail\n  path /var/log/secure\n  pos_file /var/log/host-secure.log.pos\n  <parse>\n    @type syslog\n  </parse>\n  tag host.secure\n</source>\n\n<source>\n  @type tail\n  @id in_tail_docker\n  path /var/log/docker.log\n  pos_file /var/log/fluentd-docker.log.pos\n  tag docker\n  <parse>\n    @type regexp\n    expression /^time=\"(?<time>[^)]*)\" level=(?<severity>[^ ]*) msg=\"(?<message>[^\"]*)\"( err=\"(?<error>[^\"]*)\")?( statusCode=($<status_code>\\d+))?/\n  </parse>\n</source>\n\n\n<source>\n  @type tail\n  @id in_tail_kubelet\n  multiline_flush_interval 5s\n  path /var/log/kubelet.log\n  pos_file /var/log/fluentd-kubelet.log.pos\n  tag kubelet\n  <parse>\n    @type kubernetes\n  </parse>\n</source>\n\n<filter kubernetes.**>\n  @type kubernetes_metadata\n  @id filter_kube_metadata\n  kubernetes_url \"#{ENV['FLUENT_FILTER_KUBERNETES_URL'] || 'https://' + ENV.fetch('KUBERNETES_SERVICE_HOST') + ':' + ENV.fetch('KUBERNETES_SERVICE_PORT') + '/api'}\"\n  verify_ssl \"#{ENV['KUBERNETES_VERIFY_SSL'] || true}\"\n  ca_file \"#{ENV['KUBERNETES_CA_FILE']}\"\n  skip_labels \"#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_LABELS'] || 'false'}\"\n  skip_container_metadata \"#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_CONTAINER_METADATA'] || 'false'}\"\n  skip_master_url \"#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_MASTER_URL'] || 'false'}\"\n  skip_namespace_metadata \"#{ENV['FLUENT_KUBERNETES_METADATA_SKIP_NAMESPACE_METADATA'] || 'false'}\"\n</filter>\n\n<match kubernetes.var.log.containers.**_kube-system_**>\n  @type null\n</match>\n\n<match kubernetes.var.log.containers.**_logging_**>\n  @type null\n</match>\n\n<match docker>\n  @type rewrite_tag_filter\n  <rule>\n    key $._HOSTNAME\n    pattern ^(.+)$\n    tag $1.docker\n  </rule>\n</match>\n\n<match kubelet>\n  @type rewrite_tag_filter\n  <rule>\n    key $._HOSTNAME\n    pattern ^(.+)$\n    tag $1.kubelet\n  </rule>\n</match>\n\n<match host.messages>\n  @type rewrite_tag_filter\n  <rule>\n    key $.host\n    pattern ^(.+)$\n    tag $1.messages\n  </rule>\n</match>\n\n<match host.secure>\n  @type rewrite_tag_filter\n  <rule>\n    key $.host\n    pattern ^(.+)$\n    tag $1.secure\n  </rule>\n</match>\n\n<match kubernetes.var.**>\n  @type rewrite_tag_filter\n  <rule>\n    # json structured log - consider adoption a standard json schema:\n    #    https://github.com/timberio/log-event-json-schema\n    key message\n    pattern /^\\{\\s*\"gen3log\":/\n    tag kubernetes.gen3.json.${tag}\n  </rule>\n  <rule>\n    # combined log format - default Apache and nginx structure\n    #    https://httpd.apache.org/docs/1.3/logs.html#combined\n    key message\n    pattern /^(((\\d+\\.\\d+\\.\\d+\\.\\d+)|-)\\s+){2}\\S+\\s+\\[\\d\\d?\\//\n    tag kubernetes.gen3.combined.${tag}\n  </rule>\n  <rule>\n    # unstructured log line\n    key message\n    pattern /\\S/\n    tag kubernetes.gen3.raw.${tag}\n  </rule>\n\n</match>\n\n<filter kubernetes.gen3.json.**>\n  @type record_transformer\n  <record>\n    log_type json\n    # This one doesn't work for whatever reason, if you do ${record[\"kubernetes\"]} the whole blob would be added, but can't access subobjects\n    #container_name ${record[\"kubernetes\"][\"container_name\"]}\n  </record>\n</filter>\n\n<filter kubernetes.gen3.combined.**>\n  @type record_transformer\n  <record>\n    log_type combined\n  </record>\n</filter>\n\n<filter kubernetes.gen3.raw.**>\n  @type record_transformer\n  <record>\n    log_type raw\n  </record>\n</filter>\n\n<match kubernetes.gen3.**>\n  @type rewrite_tag_filter\n  <rule>\n    key $.kubernetes.pod_name\n    pattern ^(.+)$\n    tag \"#{Time.now.strftime('%Y-%m-%d')}.$1\"\n  </rule>\n#  <rule>\n#    key $.kubernetes\n#    pattern ^(.+)$\n#    tag $1.container_name\n#  </rule>\n</match>\n\n#<match \"#{Time.now.strftime('%Y-%m-%d')}.**\">\n#  @type rewrite_tag_filter\n#  <rule>\n#    key $.kubernetes.container_name\n#    pattern ^(.+)$\n    #tag $1.${tag}\n#    tag ${tag}.$1\n#  </rule>\n#</match>\n\n# TODO:\n# * python stack traces: \"Traceback (most recent call last):\"\"\n#     https://docs.fluentd.org/v0.12/articles/parser_multiline#formatn\n#\n# Idea: add `visitor` cookie to revproxy ...\n\n\n<match **>\n  @type cloudwatch_logs\n  @id out_cloudwatch_logs\n  log_group_name \"#{ENV['LOG_GROUP_NAME']}\"\n  auto_create_stream true\n  use_tag_as_stream true\n  retention_in_days \"#{ENV['RETENTION_IN_DAYS'] || 'nil'}\"\n  json_handler yajl # To avoid UndefinedConversionError\n  log_rejected_request \"#{ENV['LOG_REJECTED_REQUEST']}\" # Log rejected request for missing parts\n</match>\n"` |  |
| fluentd.configuration.enabled | bool | `false` |  |
| fluentd.enabled | bool | `false` |  |
| fluentd.targetRevision | string | `"0.5.2"` |  |
| grafana-alloy.configuration.enabled | bool | `false` |  |
| grafana-alloy.enabled | bool | `false` |  |
| grafana-alloy.targetRevision | string | `"0.4.0"` |  |
| karpenter-crds.amiSelectorName | string | `"EKS-FIPS*"` |  |
| karpenter-crds.default.additionalTags | object | `{}` |  |
| karpenter-crds.default.consolidateAfter | string | `"30s"` |  |
| karpenter-crds.default.consolidation | bool | `true` |  |
| karpenter-crds.default.consolidationPolicy | string | `"WhenEmpty"` |  |
| karpenter-crds.default.enabled | bool | `true` |  |
| karpenter-crds.default.expireAfter | string | `"168h"` |  |
| karpenter-crds.enabled | bool | `false` |  |
| karpenter-crds.jupyter.additionalTags | object | `{}` |  |
| karpenter-crds.jupyter.consolidateAfter | string | `"30s"` |  |
| karpenter-crds.jupyter.consolidation | bool | `true` |  |
| karpenter-crds.jupyter.consolidationPolicy | string | `"WhenEmpty"` |  |
| karpenter-crds.jupyter.enabled | bool | `true` |  |
| karpenter-crds.jupyter.expireAfter | string | `"168h"` |  |
| karpenter-crds.migration | bool | `false` |  |
| karpenter-crds.selectorTag | string | `""` |  |
| karpenter-crds.targetRevision | string | `"master"` |  |
| karpenter-crds.workflow.additionalTags | object | `{}` |  |
| karpenter-crds.workflow.consolidateAfter | string | `"30s"` |  |
| karpenter-crds.workflow.consolidation | bool | `true` |  |
| karpenter-crds.workflow.consolidationPolicy | string | `"WhenEmpty"` |  |
| karpenter-crds.workflow.enabled | bool | `true` |  |
| karpenter-crds.workflow.expireAfter | string | `"168h"` |  |
| karpenter-crds.workflow.sgSelector | string | `""` |  |
| karpenter.awsRegion | string | `"us-east-1"` |  |
| karpenter.configuration.enabled | bool | `false` |  |
| karpenter.controller.image.digest | string | `"sha256:0c142050d872cb0ac7b30a188ec36aa765b449718cde0c7e49f7495b28f47c29"` |  |
| karpenter.controller.image.tag | string | `"v0.32.9"` |  |
| karpenter.enabled | bool | `false` |  |
| karpenter.resources.limits.cpu | string | `"1"` |  |
| karpenter.resources.limits.memory | string | `"1Gi"` |  |
| karpenter.resources.requests.cpu | string | `"1"` |  |
| karpenter.resources.requests.memory | string | `"1Gi"` |  |
| karpenter.targetRevision | string | `"v0.32.9"` |  |
| kube-state-metrics.configuration.enabled | bool | `false` |  |
| kube-state-metrics.enabled | bool | `false` |  |
| kube-state-metrics.targetRevision | string | `"5.28.0"` |  |
| project | string | `"unfunded"` |  |
| vpc-cni.configuration.enabled | bool | `false` |  |
| vpc-cni.enabled | bool | `false` |  |
| vpc-cni.targetRevision | string | `"v1.16.2"` |  |
