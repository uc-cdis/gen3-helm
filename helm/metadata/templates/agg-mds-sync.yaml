{{- if .Values.useAggMds }}
apiVersion: v1
kind: ConfigMap
metadata: 
  name: agg-mds-config
data:
  aggregate_config.json: |
   {{ .Values.aggMdsConfig | default "{}" | nindent 4 }}
---
apiVersion: batch/v1
kind: CronJob
metadata:
  name: metadata-aggregate-sync
spec:
  schedule: "0 0 1 1 */5"
  jobTemplate:
    spec:
      template:
        metadata:
          labels:
            app: gen3job
        spec:
          affinity:
            nodeAffinity:
              preferredDuringSchedulingIgnoredDuringExecution:
              - weight: 100
                preference:
                  matchExpressions:
                  - key: karpenter.sh/capacity-type
                    operator: In
                    values:
                    - on-demand
              - weight: 99
                preference:
                  matchExpressions:
                  - key: eks.amazonaws.com/capacityType
                    operator: In
                    values:
                    - ONDEMAND
          volumes:
            - name: config-volume
              configMap:
                name: agg-mds-config
            - name: shared-data
              emptyDir: {}
          initContainers:
            - name: wait-for-es
              image: alpine/curl
              env:
                - name: GEN3_ES_ENDPOINT
                  value: {{ .Values.esEndpoint | default "http://gen3-elasticsearch-master:9200" }}
              imagePullPolicy: IfNotPresent
              command: ["/bin/sh"]
              args:
                - "-c"
                - |
                  echo "Waiting for Elasticsearch to be ready..."
                  until curl -s -XGET $GEN3_ES_ENDPOINT; do
                    echo "Elasticsearch is not ready yet..."
                    sleep 5
                  done
                  echo "Elasticsearch is ready!"
            - name: wait-for-metadata
              image: alpine/curl
              env:
                - name: GEN3_ES_ENDPOINT
                  value: {{ .Values.esEndpoint | default "http://gen3-elasticsearch-master:9200" }}
              imagePullPolicy: IfNotPresent
              command: ["/bin/sh"]
              args:
                - "-c"
                - |
                  echo "Waiting for metadata service to be ready"
                  until curl -s -XGET http://metadata-service; do
                    echo "Metadata service is not ready yet..."
                    sleep 5
                  done
          containers:
            - name: metadata-sync
              image: "{{ .Values.image.repository }}:{{ .Values.image.tag | default .Chart.AppVersion }}"
              volumeMounts:
                # - name: config-volume-g3auto
                #   readOnly: true
                #   mountPath: /src/.env
                #   subPath: metadata.env
                - name: config-volume
                  readOnly: true
                  mountPath: /aggregate_config.json
                  subPath: aggregate_config.json
                # - name: config-manifest
                #   readOnly: true
                #   mountPath: /metadata.json
                #   subPath: json
                - name: shared-data
                  mountPath: /mnt/shared
              env:
                - name: GEN3_DEBUG
                  value: "False"
                - name: GEN3_ES_ENDPOINT
                  value: {{ .Values.esEndpoint | default "http://gen3-elasticsearch-master:9200" }}
                - name: USE_AGG_MDS
                  value: {{ (.Values.useAggMds | quote | default "True") }}
                - name: AGG_MDS_NAMESPACE
                  value: {{ .Values.aggMdsNamespace | default .Release.Name }}
              imagePullPolicy: Always
              command: ["/bin/sh"]
              args:
                - "-c"
                - |
                  cat /aggregate_config.json
                  /env/bin/python /src/src/mds/populate.py --config /aggregate_config.json
                  if [ $? -ne 0 ]; then
                    echo "WARNING: non zero exit code: $?"
                    echo "WARNING: non zero exit code: $?" > /mnt/shared/status
                  else
                    echo "Success" > /mnt/shared/status
                  fi
            - name: slack-alert
              env:
                - name: slackWebHook
                  valueFrom:
                      configMapKeyRef:
                        name: global
                        key: slack_webhook
                        optional: true
                - name: gen3Env
                  valueFrom:
                      configMapKeyRef:
                        name: manifest-global
                        key: hostname
                        optional: true
              image: quay.io/cdis/awshelper:master
              volumeMounts:
                - name: shared-data
                  mountPath: /mnt/shared
              command: ["/bin/bash"]
              args:
                - "-c"
                - |
                  if [[ ! "$slackWebHook" =~ ^http ]]; then
                    echo "Slack webhook not set"
                    exit 0
                  fi
                  while [ ! -f /mnt/shared/status ]; do
                    echo "Waiting for status file..."
                    sleep 5
                  done
                  if ! [[ $(cat /mnt/shared/status) =~ "Success" ]]; then
                    success="SUCCESS"
                    color="2EB67D"
                  else
                    success="FAILED"
                    color="FF0000"
                  fi
                  echo "Sending ${success} message to slack..."
                  payload="{\"attachments\": [{\"fallback\": \"JOB ${success}: metadata-aggregate-sync cronjob on ${gen3Env}\",\"color\": \"#${color}\",\"title\": \"JOB ${success}: metadata-aggregate-sync cronjob on ${gen3Env}\",\"text\": \"Pod name: ${HOSTNAME}\",\"ts\": \"$(date +%s)\"}]}"
                  echo "Payload=${payload}"
                  curl -X POST --data-urlencode "payload=${payload}" "${slackWebHook}"
          restartPolicy: Never
{{- end}}